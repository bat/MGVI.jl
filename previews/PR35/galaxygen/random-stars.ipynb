{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will fit the [coal mining disaster dataset](coal_mining_data.tsv) with a Gaussian process modulated\n",
    "Poisson process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing:\n",
    "* MGVI for the posterior fit\n",
    "* `Distributions.jl` and `FFTW.jl` to define the statistical model\n",
    "* `Optim.jl` to pass `Optim.Options` to MGVI and to find Maximum a posteriori fit that we will use for comparison\n",
    "* `StatsBase.jl` for histogram construction from the data and also for error bands visualization\n",
    "* `Plots.jl` for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MGVI\n",
    "\n",
    "using FillArrays\n",
    "using DelimitedFiles\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using StatsBase\n",
    "using Distributions\n",
    "using Optim\n",
    "\n",
    "using Plots\n",
    "using Plots.PlotMeasures\n",
    "Plots.default(legendfontsize=10, tickfontsize=10, grid=false, dpi=120, size=(500, 300))\n",
    "\n",
    "using FFTW\n",
    "\n",
    "import ForwardDiff\n",
    "import Zygote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(84612);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset, which is included with this repository, contains intervals in days between\n",
    "disasters occuring at British coal mines between March 1851 and March 1962.\n",
    "We build a model by splitting the entire time range into intervals of 365 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global parameters and the grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define several model properties:\n",
    "* `DATA_DIM` is the shape of the dataset\n",
    "* `DATA_XLIM` specifies the time range of the data\n",
    "* `GP_GRAIN_FACTOR` determines the numbers of finer bins which a data bin is split into.\n",
    "   This is useful when there are several datasets defined on different grids.\n",
    "* `GP_PADDING` adds empty paddings to the dataset. We use a Fourier transform to sample from the Gaussian process\n",
    "   with a finite correlation length. `GP_PADDING` helps us to ensure that periodic boundary conditions\n",
    "   imposed by a Fourier transform won't affect the data region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIM = (200, 200);\n",
    "\n",
    "DATA_XLIM = ((-1., 1.), (0., 2.));\n",
    "\n",
    "GP_GRAIN_FACTOR = (2, 3);\n",
    "GP_PADDING = (2., 1.);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function produce_bins_1d(data_xlim, data_dim, gp_grain_factor, gp_padding)\n",
    "    data_binsize = (data_xlim[2] - data_xlim[1])/data_dim\n",
    "    gp_binsize = data_binsize/gp_grain_factor\n",
    "    gp_dim = Integer(((data_xlim[2] - data_xlim[1]) + 2*gp_padding) ÷ gp_binsize)\n",
    "    gp_left_bin_offset = gp_right_bin_offset = (gp_dim - data_dim) ÷ 2\n",
    "    if (2*gp_left_bin_offset + data_dim*gp_grain_factor) % 2 == 1\n",
    "        gp_left_bin_offset += 1\n",
    "    end\n",
    "    gp_left_xlim = data_xlim[1] - gp_left_bin_offset*gp_binsize\n",
    "    gp_right_xlim = data_xlim[2] + gp_right_bin_offset*gp_binsize\n",
    "    gp_left_xs = collect(gp_left_xlim + gp_binsize/2:gp_binsize:data_xlim[1])\n",
    "    gp_right_xs = collect(data_xlim[2] + gp_binsize/2:gp_binsize:gp_right_xlim)\n",
    "    gp_data_xs = collect(data_xlim[1] + gp_binsize/2:gp_binsize:data_xlim[2])\n",
    "    gp_xs = [gp_left_xs; gp_data_xs; gp_right_xs]\n",
    "    data_idxs = collect(gp_left_bin_offset+1:gp_grain_factor:gp_left_bin_offset+data_dim*gp_grain_factor)\n",
    "    gp_xs, gp_binsize, data_idxs\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function produce_bins()\n",
    "    all_gp_xs = []\n",
    "    all_gp_binsize = []\n",
    "    all_data_idxs = []\n",
    "    for i in 1:size(DATA_DIM, 1)\n",
    "        gp_xs, gp_binsize, data_idxs = produce_bins_1d(DATA_XLIM[i], DATA_DIM[i], GP_GRAIN_FACTOR[i], GP_PADDING[i])\n",
    "        push!(all_gp_xs, gp_xs)\n",
    "        push!(all_gp_binsize, gp_binsize)\n",
    "        push!(all_data_idxs, data_idxs)\n",
    "    end\n",
    "    tuple(all_gp_xs...), tuple(all_gp_binsize...), tuple(all_data_idxs...)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the defined model properties, we generate the grid. GP grid is the fine-grained grid\n",
    "with offsets added to the data range.\n",
    "* `_GP_XS` represent bin centers of such a fine-grained grid\n",
    "* `_GP_BINSIZE` is the width of the bin (that is 1/`GP_GRAIN_FACTOR` of data bin size)\n",
    "* `_DATA_IDXS` - integer indices of the left edges of the data bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_GP_XS, _GP_BINSIZE, _DATA_IDXS = produce_bins();\n",
    "_GP_DIM = length.(_GP_XS);\n",
    "_HARMONIC_DIST = 1 ./ (_GP_DIM .* _GP_BINSIZE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_HARMONIC_DIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gaussian process in this tutorial is modeled in the Fourier space with zero mean\n",
    "and two hyperparameters defining properties of its kernel. To sample from this\n",
    "Gaussian process, we also need a parameter per bin that will represent the particular\n",
    "realization of the GP in the bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function assemble_paridx(;kwargs...)\n",
    "    pos = 0\n",
    "    res = []\n",
    "    for (k, v) in kwargs\n",
    "        new_start, new_stop = v.start+pos, v.stop+pos\n",
    "        push!(res, (k, (v.start+pos):(v.stop+pos)))\n",
    "        pos = new_stop\n",
    "    end\n",
    "    (;res...)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MGVI is an iterative procedure, so we will need to introduce an initial guess for the state of the model.\n",
    "We create a vector with size equal to the count of all parameters' `starting_point` and a NamedTuple\n",
    "`PARDIX` that assigns names to the sub-regions in this vector. In the correct case:\n",
    "* `gp_hyper` is two hyperparameters of the Gaussian process stored in the first two cells of the parameter vector\n",
    "* `gp_latent` `_GP_DIM` are parameters used to define the particular realization of the gaussian process,\n",
    "   stored at indices between `3` to `2 + _GP_DIM`.\n",
    "\n",
    "Function `assemble_paridx` is responsible for constructing such a NamedTuple from the parameter specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARIDX = assemble_paridx(gp_hyper=1:4, gp_latent=1:prod(_GP_DIM));\n",
    "\n",
    "starting_point = randn(last(PARIDX).stop);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function map_idx(idx::Real, idx_range::AbstractUnitRange{<:Integer})\n",
    "    i = idx - minimum(idx_range)\n",
    "    n = length(eachindex(idx_range))\n",
    "    n_2 = n >> 1\n",
    "    ifelse(i <= n_2, i, i - n)\n",
    "end\n",
    "\n",
    "function dist_k(idx::CartesianIndex, ax::NTuple{N,<:AbstractUnitRange{<:Integer}}, harmonic_distances::NTuple{N,<:Real}) where N\n",
    "    mapped_idx = map(map_idx, Tuple(idx), ax)\n",
    "    norm(map(*, mapped_idx, harmonic_distances))\n",
    "end\n",
    "\n",
    "function dist_array(dims::NTuple{N,<:Real}, harmonic_distances::NTuple{N,<:Real}) where N\n",
    "    cart_idxs = CartesianIndices(map(Base.OneTo, dims))\n",
    "    dist_k.(cart_idxs, Ref(axes(cart_idxs)), Ref(harmonic_distances))\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Gaussian process's covariance in the Fourier space is represented with a diagonal matrix. Values\n",
    "on the diagonal follow a squared exponential function with parameters depending on priors.\n",
    "A kernel that is diagonal and mirrored around the center represents a periodic and translationally invariant function\n",
    "in the coordinate space. This property restricts covariance to have a finite correlation length in the coordinate\n",
    "space.\n",
    "\n",
    "The kernel in the Fourier space is defined on the domain of wave numbers `k`. We model the mirror-symmetrical kernel\n",
    "by imposing the mirror symmetry on the vector of the wave numbers. (See `map_idx` for the symmetry implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = dist_array(_GP_DIM, _HARMONIC_DIST);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MGVI assumes that all priors are distributed as standard normals `N(0, 1)`; thus,\n",
    "to modify the shapes of the priors, we explicitly rescale them at the model implementation phase.\n",
    "\n",
    "We also exponentiate each prior before using it to tune the squared exponential shape. In doing so,\n",
    "we ensure only positive values for the kernel's hyperparameters.\n",
    "\n",
    "Actually, for the sake of numeric stability we model already square root of the covariance.\n",
    "This can be traced by missing `sqrt` in the next level, where we sample from the Gaussian process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function amplitude_spectrum(d::Real, zero_mode_std::Real, slope::Real, offset::Real)\n",
    "    # ampl * sqrt(2 * π * corrlen) * exp( -π^2 * d^2 * corrlen^2)\n",
    "    ifelse(d ≈ 0, promote(zero_mode_std, exp(offset + slope * log(d)))...)\n",
    "end;\n",
    "\n",
    "function sqrt_kernel(p)\n",
    "    _, kernel_zero_mode_std_c, kernel_slope_c, kernel_offset_c = p[PARIDX.gp_hyper]\n",
    "    kernel_zero_mode_std = exp(kernel_zero_mode_std_c)*0.5 + 0.2\n",
    "    kernel_slope = kernel_slope_c/5 - 2\n",
    "    kernel_offset = kernel_offset_c/5 - 2\n",
    "    amplitude_spectrum.(k, kernel_zero_mode_std, kernel_slope, kernel_offset)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a Fourier transform we choose the Discrete Hartley Transform, which ensures that Fourier\n",
    "coefficients of the real valued function remain real valued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = FFTW.plan_r2r(zeros(_GP_DIM), FFTW.DHT);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed, let's have a brief look at the kernel's shape. Below\n",
    "we plot the kernel in the coordinate space `K(r) = K(x2 - x1)` as a function of time in years\n",
    "between two points. As we go further along the `x`-axis, the time interval will increase, and\n",
    "the covariance will decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function plot_kernel_model_x(p, x_i; plot_args=(;))\n",
    "    xs = _GP_XS[2]\n",
    "    plot!(xs, (ht * (sqrt_kernel(p)))[x_i, 1:end] .* _HARMONIC_DIST[1], label=nothing, linewidth=2.5; plot_args...)\n",
    "end\n",
    "\n",
    "function plot_kernel_model_y(p, y_i; plot_args=(;))\n",
    "    xs = _GP_XS[1]\n",
    "    plot!(xs, (ht * (sqrt_kernel(p)))[1:end, y_i] .* _HARMONIC_DIST[2], label=nothing, linewidth=2.5; plot_args...)\n",
    "end\n",
    "\n",
    "\n",
    "plot()\n",
    "p1 = plot_kernel_model_x(starting_point, 5)\n",
    "plot()\n",
    "p2 = plot_kernel_model_y(starting_point, 10)\n",
    "plot(p1, p2, layout=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it even more visual, we also plot the structure of the covariance matrix as a heatmap.\n",
    "We see that the finite correlation length shows up as a band around the diagonal. We also\n",
    "see small artifacts in the antidiagonal corners. These come from the assumption that the\n",
    "kernel is periodic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function plot_kernel_matrix(p)\n",
    "    xkernel = ht * (sqrt_kernel(p)) .* prod(_HARMONIC_DIST)\n",
    "    heatmap!(_GP_XS[1], _GP_XS[2], reshape(xkernel, _GP_DIM); yflip=true, xmirror=true, tick_direction=:out, top_margin=20px, right_margin=30px)\n",
    "end\n",
    "\n",
    "plot()\n",
    "plot_kernel_matrix(starting_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we defined the square root of the kernel function (`sqrt_kernel`),\n",
    "we just follow the regular procedure of sampling from the normal distribution.\n",
    "Since the covariance matrix in the Fourier space is diagonal, Gaussian variables\n",
    "in each bin are independent of each other. Thus, sampling ends up rescaling\n",
    "the `gp_latent` part of the prior vector responsible for the Gaussian process state.\n",
    "\n",
    "After we produced a sample of Gaussian random values following the kernel model,\n",
    "we apply a Fourier transform to return back to the coordinate space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_mode_matrix = zeros(_GP_DIM)\n",
    "zero_mode_matrix[1,1] = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function gp_sample(p)\n",
    "    zero_mode_mean = p[PARIDX.gp_hyper][1]\n",
    "    flat_gp = sqrt_kernel(p) .* reshape(p[PARIDX.gp_latent], _GP_DIM)\n",
    "    flat_gp = flat_gp + zero_mode_matrix*exp(zero_mode_mean/10+0.3)*60\n",
    "    pixel_volume = prod(_HARMONIC_DIST)\n",
    "    (ht * flat_gp) .* pixel_volume\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Together with the implementation of `gp_sample` we also need\n",
    "to define its version of the `Dual`s. This will allow our\n",
    "application of the Hartley transform to be differentiatiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function gp_sample(dp::Vector{ForwardDiff.Dual{T, V, N}}) where {T,V,N}\n",
    "    pixel_volume = prod(_HARMONIC_DIST)\n",
    "    zero_mode_mean = dp[PARIDX.gp_hyper][1]\n",
    "    flat_gp_duals = sqrt_kernel(dp) .* reshape(dp[PARIDX.gp_latent], _GP_DIM)\n",
    "    flat_gp_duals = flat_gp_duals + zero_mode_matrix*exp(zero_mode_mean/10+0.3)*60\n",
    "    val_res = (ht*ForwardDiff.value.(flat_gp_duals)) .* pixel_volume\n",
    "    psize = size(ForwardDiff.partials(flat_gp_duals[1]), 1)\n",
    "    ps = x -> ForwardDiff.partials.(flat_gp_duals, x)\n",
    "    val_ps = map((x -> ht*ps(x) .* pixel_volume), 1:psize)\n",
    "    ForwardDiff.Dual{T}.(val_res, val_ps...)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian process realization is meant to serve as a Poisson rate of the Poisson\n",
    "process. Since the Gaussian process is not restricted to positive values, we\n",
    "exponentiate its values to forcefully make the function positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function poisson_gp_link(fs)\n",
    "    exp.(fs)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we have a function representing the Poisson rate density,\n",
    "we have to integrate it over each data bin to define the Poisson rate in these bins.\n",
    "Function `agg_lambdas` does precisely that. When `GP_GRAIN_FACTOR = 1`, this function\n",
    "just multiplies the value of the Gaussian process in the bin by the `_GP_BINSIZE`.\n",
    "When we have more GP bins per data bin (`GP_GRAIN_FACTOR > 1`), then we apply\n",
    "rectangular quadrature to integrate over the bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function forward_agg(data, origin_idx, block_size)\n",
    "    sum(data[Base.UnitRange.(origin_idx, origin_idx .+ block_size)...])\n",
    "end;\n",
    "\n",
    "function agg_lambdas(lambdas)\n",
    "    gps = [forward_agg(lambdas, block_idx, GP_GRAIN_FACTOR) for block_idx in Iterators.product(_DATA_IDXS...)] .* prod(_GP_BINSIZE)\n",
    "    xs = getindex.(_GP_XS, map(p -> p[1] .+ p[2], zip(_DATA_IDXS, GP_GRAIN_FACTOR .÷ 2)))\n",
    "    xs, gps\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zygote fails on Iterators.product:\n",
    "# https://github.com/FluxML/Zygote.jl/pull/785\n",
    "# code borrowed from here:\n",
    "# https://github.com/FluxML/Zygote.jl/issues/421#issuecomment-727635455\n",
    "\n",
    "Zygote.@adjoint function Iterators.product(xs...)\n",
    "  back(::AbstractArray{Nothing}) = nothing\n",
    "  back(dy::NamedTuple{(:iterators,)}) = dy.iterators\n",
    "  function back(dy::AbstractArray)\n",
    "    d = 1\n",
    "    ntuple(length(xs)) do n\n",
    "      first(dy)[n] === nothing && return nothing\n",
    "      nd = _ndims(xs[n])\n",
    "      dims = ntuple(i -> i<d ? i : i+nd, ndims(dy)-nd)\n",
    "      d += nd\n",
    "      init = zero.(first(dy)[n]) # allows for tuples, which accum can add:\n",
    "      red = mapreduce(StaticGetter{n}(), accum, dy; dims=dims, init=init)\n",
    "      return reshape(red, axes(xs[n]))\n",
    "    end\n",
    "  end\n",
    "  Iterators.product(xs...), back\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define the model by using the building blocks defined above:\n",
    "* `gp_sample` sample from the Gaussian process with defined `sqrt_kernel` covariance\n",
    "* `poisson_gp_link` ensures Gaussian process is positive\n",
    "* `agg_lambdas` integrates Gaussian process over each data bin to turn it into a Poisson rate for each bin\n",
    "* `model` maps parameters into the product of the Poisson distribution's counting events in each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function model(params)\n",
    "    fs = gp_sample(params)\n",
    "    fine_lambdas = poisson_gp_link(fs)\n",
    "    xs, lambdas = agg_lambdas(fine_lambdas)\n",
    "    Product(Poisson.(lambdas)[:])\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_params = randn(last(PARIDX).stop);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(true_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rand(model(true_params));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(reshape(data, DATA_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_avg_likelihood(model, samples, data)\n",
    "    tot = 0\n",
    "    for sample in eachcol(samples)\n",
    "        tot += -MGVI.posterior_loglike(model, sample, data)\n",
    "    end\n",
    "    tot/size(samples, 2)\n",
    "end;\n",
    "\n",
    "function show_avg_likelihood(series)\n",
    "    scatter!(1:size(series, 1), series, label=\"-loglike\")\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_iteration = mgvi_kl_optimize_step(Random.GLOBAL_RNG,\n",
    "                                        model, data,\n",
    "                                        starting_point;\n",
    "                                        num_residuals=3,\n",
    "                                        jacobian_func=FwdRevADJacobianFunc,\n",
    "                                        residual_sampler=ImplicitResidualSampler,\n",
    "                                        optim_options=Optim.Options(iterations=1, show_trace=false),\n",
    "                                        residual_sampler_options=(;cg_params=(;abstol=1E-2,verbose=false)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_iteration = first_iteration;\n",
    "avg_likelihood_series = [];\n",
    "push!(avg_likelihood_series, compute_avg_likelihood(model, next_iteration.samples, data));\n",
    "for i in 1:100\n",
    "    tmp_iteration = mgvi_kl_optimize_step(Random.GLOBAL_RNG,\n",
    "                                          model, data,\n",
    "                                          next_iteration.result;\n",
    "                                          num_residuals=6,\n",
    "                                          jacobian_func=FwdRevADJacobianFunc,\n",
    "                                          residual_sampler=ImplicitResidualSampler,\n",
    "                                          optim_options=Optim.Options(iterations=10, show_trace=false),\n",
    "                                          residual_sampler_options=(;cg_params=(;abstol=1E-4,verbose=false)))\n",
    "    global next_iteration = tmp_iteration\n",
    "    push!(avg_likelihood_series, compute_avg_likelihood(model, next_iteration.samples, data))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(yscale=:log)\n",
    "show_avg_likelihood(avg_likelihood_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in avg_likelihood_series\n",
    "    print(i, \"\\n\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
